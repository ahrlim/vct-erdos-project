{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/vct_2023/processed_data/AvsB_train_data_players_stats_eco_SK_rounds.csv\")\n",
    "test_data = pd.read_csv(\"../data/vct_2023/processed_data/AvsB_test_data_players_stats_eco_SK_rounds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id_columns = [\"Tournament\", \"Stage\", \"Match Type\", \"Match Name\", \"Team_A\", \"Team_B\"]\n",
    "map_composition = [\"Map\", \"Composition_A\", \"Composition_B\"]\n",
    "outcome_columns = [\"Team_A_score_diff\", \"Team_B_score_diff\", \"Team_A_win\", \"Team_B_win\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train_data.drop(game_id_columns+map_composition+outcome_columns, axis=1)\n",
    "train_target = train_data[\"Team_A_win\"]\n",
    "\n",
    "test_input = test_data.drop(game_id_columns+map_composition+outcome_columns, axis=1)\n",
    "test_target = test_data[\"Team_A_win\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert len(train_input.keys()) == len(test_input.keys()), \"The number of train and test input are different.\"\n",
    "assert set(train_input.keys()) == set(test_input.keys()), \"Train and test have different input feature.\"\n",
    "assert len(train_input) == len(train_target), \"Train input and target sizes are different.\"\n",
    "assert len(test_input) == len(test_target), \"Test input and target sizes are different.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if input has non numeric features.\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "for key in train_input.keys():\n",
    "    if not is_numeric_dtype(train_input[key]):\n",
    "        print(key, \"is not numeric.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_stats = [\"Rating_A\", \"Rating_B\",\"Average Combat Score_A\", \"Average Combat Score_B\",\n",
    "                \"Kill, Assist, Trade, Survive %_A\", \"Kill, Assist, Trade, Survive %_B\",\n",
    "                \"Average Damage Per Round_A\", \"Average Damage Per Round_B\",\n",
    "                \"Kills Per Round_A\", \"Kills Per Round_B\",\n",
    "                \"Assists Per Round_A\", \"Assists Per Round_B\",\n",
    "                \"First Kills Per Round_A\", \"First Kills Per Round_B\",\n",
    "                \"First Deaths Per Round_A\", \"First Deaths Per Round_B\",\n",
    "                \"Headshot %_A\", \"Headshot %_B\",\n",
    "                \"Clutch Success %_A\", \"Clutch Success %_B\"]\n",
    "\n",
    "for i in range(len(players_stats)//2):\n",
    "    '''\n",
    "    We take only one pair of players' stats at a time and train models.\n",
    "    We will do train test split on the train set to address data leakage issue.\n",
    "    '''\n",
    "    features = players_stats[2*i:2*(i+1)]\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression())])\n",
    "\n",
    "    dict_classifiers = {\n",
    "        \"Logreg\": pipeline,\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"DTree\": DecisionTreeClassifier(),\n",
    "        \"RForest\": RandomForestClassifier(),\n",
    "        \"XGB\": XGBClassifier()\n",
    "        }\n",
    "    \n",
    "    X = train_input[features]\n",
    "    y = train_target\n",
    "    X_test = test_input[features]\n",
    "    y_test = test_target\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, random_state=100)\n",
    "\n",
    "\n",
    "    \n",
    "    best_acc = 0\n",
    "    second_best_acc = 0\n",
    "    best_features = None\n",
    "    second_best_features = None\n",
    "    best_clf = None\n",
    "    second_best_clf = None\n",
    "\n",
    "    best_val_acc = 0\n",
    "    best_val_feature = None\n",
    "    best_val_clf = None\n",
    "\n",
    "    for clf_name, clf in dict_classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        val_pred = clf.predict(X_val)\n",
    "        test_pred = clf.predict(X_test)\n",
    "        val_acc = accuracy_score(y_val, val_pred)\n",
    "        test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "        if test_acc >= best_acc:\n",
    "            temp_acc = best_acc\n",
    "            best_acc = test_acc\n",
    "            second_best_acc = temp_acc\n",
    "\n",
    "            temp_features = best_features\n",
    "            best_features = features\n",
    "            second_best_features = temp_features\n",
    "\n",
    "            temp_clf = best_clf\n",
    "            best_clf = clf\n",
    "            second_best_clf = temp_clf\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_val_feature = features\n",
    "            best_val_clf = clf\n",
    "\n",
    "    # Uncomment the lines below to see\n",
    "    # accuracies and prediction means of validation set and test set in each step\n",
    "    #\n",
    "    #     print(\"----------------------------------------\")\n",
    "    #     print(f\"Classifier: {clf_name}\")\n",
    "    #     print(f\"trained on {features}\")\n",
    "    #     print(\" - - - - - - - - - - - - - - - - -\")\n",
    "    #     print(f\"Validation accuracy: {val_acc}\")\n",
    "    #     print(f\"y_val mean: {np.mean(y_val)}\")\n",
    "    #     print(f\"Validation prediction mean: {np.mean(val_pred)}\")\n",
    "    #     print(\" - - - - - - - - - - - - - - - - -\")\n",
    "    #     print(f\"Test accuracy: {test_acc}\")\n",
    "    #     print(f\"y_test mean: {np.mean(y_test)}\")\n",
    "    #     print(f\"Test prediction mean: {np.mean(test_pred)}\")\n",
    "        \n",
    "    # print(\"===============================================\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Clutch Success %_A', 'Clutch Success %_B'],\n",
       " ['Clutch Success %_A', 'Clutch Success %_B'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features, second_best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DecisionTreeClassifier(),\n",
       " 0.5833333333333334,\n",
       " KNeighborsClassifier(),\n",
       " 0.5833333333333334)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf, best_acc, second_best_clf, second_best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.679144385026738"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the above cell. Difference is we continuously adding more features.\n",
    "\n",
    "players_stats = [\"Rating_A\", \"Rating_B\",\"Average Combat Score_A\", \"Average Combat Score_B\",\n",
    "                \"Kill, Assist, Trade, Survive %_A\", \"Kill, Assist, Trade, Survive %_B\",\n",
    "                \"Average Damage Per Round_A\", \"Average Damage Per Round_B\",\n",
    "                \"Kills Per Round_A\", \"Kills Per Round_B\",\n",
    "                \"Assists Per Round_A\", \"Assists Per Round_B\",\n",
    "                \"First Kills Per Round_A\", \"First Kills Per Round_B\",\n",
    "                \"First Deaths Per Round_A\", \"First Deaths Per Round_B\",\n",
    "                \"Headshot %_A\", \"Headshot %_B\",\n",
    "                \"Clutch Success %_A\", \"Clutch Success %_B\"]\n",
    "\n",
    "for i in range(len(players_stats)//2):\n",
    "    '''\n",
    "    We take only one pair of players' stats at a time and train models.\n",
    "    We will do train test split on the train set to address data leakage issue.\n",
    "    '''\n",
    "    features = players_stats[0:2*(i+1)]\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression())])\n",
    "\n",
    "    dict_classifiers = {\n",
    "        \"Logreg\": pipeline,\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"DTree\": DecisionTreeClassifier(),\n",
    "        \"RForest\": RandomForestClassifier(),\n",
    "        \"XGB\": XGBClassifier()\n",
    "        }\n",
    "    \n",
    "    X = train_input[features]\n",
    "    y = train_target\n",
    "    X_test = test_input[features]\n",
    "    y_test = test_target\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, random_state=300)\n",
    "\n",
    "\n",
    "    best_acc = 0\n",
    "    second_best_acc = 0\n",
    "    best_features = None\n",
    "    second_best_features = None\n",
    "    best_clf = None\n",
    "    second_best_clf = None\n",
    "\n",
    "    for clf_name, clf in dict_classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        val_pred = clf.predict(X_val)\n",
    "        test_pred = clf.predict(X_test)\n",
    "        val_acc = accuracy_score(y_val, val_pred)\n",
    "        test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "\n",
    "        if test_acc >= best_acc:\n",
    "            temp_acc = best_acc\n",
    "            best_acc = test_acc\n",
    "            second_best_acc = temp_acc\n",
    "\n",
    "            temp_features = best_features\n",
    "            best_features = features\n",
    "            second_best_features = temp_features\n",
    "\n",
    "            temp_clf = best_clf\n",
    "            best_clf = clf\n",
    "            second_best_clf = temp_clf\n",
    "\n",
    "\n",
    "    #     print(\"----------------------------------------\")\n",
    "    #     print(f\"Classifier: {clf_name}\")\n",
    "    #     print(f\"trained on {features}\")\n",
    "    #     print(\" - - - - - - - - - - - - - - - - -\")\n",
    "    #     print(f\"Validation accuracy: {val_acc}\")\n",
    "    #     print(f\"y_val mean: {np.mean(y_val)}\")\n",
    "    #     print(f\"Validation prediction mean: {np.mean(val_pred)}\")\n",
    "    #     print(\" - - - - - - - - - - - - - - - - -\")\n",
    "    #     print(f\"Test accuracy: {test_acc}\")\n",
    "    #     print(f\"y_test mean: {np.mean(y_test)}\")\n",
    "    #     print(f\"Test prediction mean: {np.mean(test_pred)}\")\n",
    "        \n",
    "    # print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "               num_parallel_tree=None, random_state=None, ...),\n",
       " 0.6428571428571429,\n",
       " KNeighborsClassifier(),\n",
       " 0.5595238095238095)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf, best_acc, second_best_clf, second_best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rating_A',\n",
       " 'Rating_B',\n",
       " 'Average Combat Score_A',\n",
       " 'Average Combat Score_B',\n",
       " 'Kill, Assist, Trade, Survive %_A',\n",
       " 'Kill, Assist, Trade, Survive %_B',\n",
       " 'Average Damage Per Round_A',\n",
       " 'Average Damage Per Round_B',\n",
       " 'Kills Per Round_A',\n",
       " 'Kills Per Round_B',\n",
       " 'Assists Per Round_A',\n",
       " 'Assists Per Round_B',\n",
       " 'First Kills Per Round_A',\n",
       " 'First Kills Per Round_B',\n",
       " 'First Deaths Per Round_A',\n",
       " 'First Deaths Per Round_B',\n",
       " 'Headshot %_A',\n",
       " 'Headshot %_B',\n",
       " 'Clutch Success %_A',\n",
       " 'Clutch Success %_B']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dff9a28c025b256e3dd07773b16d01fc7f1d9c1504d50adf5be320b8d91345d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

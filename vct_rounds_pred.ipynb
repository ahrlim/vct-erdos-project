{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd83fbe6-c064-4bc7-ad90-9fae95972aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd324ec-1c0a-4016-a98d-ac326395e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_rounds = pd.read_csv(\"../data/vct_2023/matches/eco_rounds.csv\")\n",
    "eco_rounds[\"Outcome\"] = eco_rounds[\"Outcome\"].apply(lambda x: 1 if x == \"Win\" else 0)\n",
    "eco_rounds[\"Loadout Value\"] = eco_rounds[\"Loadout Value\"].apply(lambda x: int(x.replace(\".\",\"\").replace(\"k\",\"00\")))\n",
    "eco_rounds[\"Remaining Credits\"] = eco_rounds[\"Remaining Credits\"].apply(lambda x: int(x.replace(\".\",\"\").replace(\"k\",\"00\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2e89da-190d-4502-8ae5-af908a93b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_scores = pd.read_csv(\"../data/vct_2023/matches/maps_scores.csv\")\n",
    "team_ab_2023 = maps_scores[[\"Tournament\", \"Stage\", \"Match Type\", \"Match Name\", \"Map\", \"Team A\", \"Team B\", \"Team A Score\", \"Team B Score\"]]\n",
    "keys = ['Tournament', 'Stage', 'Match Type', 'Match Name', 'Map','Team']\n",
    "\n",
    "for i in range(40):\n",
    "    team_ab_2023 =\\\n",
    "    pd.merge(\n",
    "        team_ab_2023.rename(columns={\"Team A\":\"Team\"})\\\n",
    "        ,eco_rounds[eco_rounds[\"Round Number\"] == i+1].drop(columns=\"Round Number\")\\\n",
    "        ,on=keys\n",
    "        ,how='left'\n",
    "    )\\\n",
    "    .rename(columns={\"Loadout Value\":f\"R{i+1}_A_lo\", \"Remaining Credits\":f\"R{i+1}_A_rc\", \"Type\":f\"R{i+1}_A_et\", \"Outcome\":f\"R{i+1}_A_win\"})\\\n",
    "    .rename(columns={\"Team\":\"Team A\", \"Team B\":\"Team\"})\\\n",
    "    .set_index(['Tournament', 'Stage', 'Match Type', 'Match Name', 'Map','Team'])\\\n",
    "    .join(eco_rounds[eco_rounds[\"Round Number\"] == i+1].drop(columns=\"Round Number\")\\\n",
    "        .set_index(['Tournament', 'Stage', 'Match Type', 'Match Name', 'Map','Team'])\\\n",
    "    )\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"Loadout Value\":f\"R{i+1}_B_lo\", \"Remaining Credits\":f\"R{i+1}_B_rc\", \"Type\":f\"R{i+1}_B_et\", \"Outcome\":f\"R{i+1}_B_win\"})\\\n",
    "    .rename(columns={\"Team\":\"Team B\"})\\\n",
    "\n",
    "team_ab_2023[\"Team_A_win\"] = (team_ab_2023[\"Team A Score\"] - team_ab_2023[\"Team B Score\"]) > 0\n",
    "team_ab_2023[\"Team_B_win\"] = (team_ab_2023[\"Team B Score\"] - team_ab_2023[\"Team A Score\"]) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1bbedca-8366-4874-abb8-07aadf22f065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swamp\\AppData\\Local\\Temp\\ipykernel_17984\\2092538396.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  j['total_rounds'] = j['Team A Score'] + j['Team B Score']\n"
     ]
    }
   ],
   "source": [
    "j=team_ab_2023[team_ab_2023.R1_A_win.isna()==False]\n",
    "j['total_rounds'] = j['Team A Score'] + j['Team B Score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "841781ee-d2b7-4d1b-bd4a-5d37b6c44157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of true values: 0.4838709677419355\n",
      "mean of predicted values: 0.5032258064516129\n",
      "accuracy: 0.7483870967741936\n",
      "coefficients: [[1.21112434 0.484979   0.82905451 0.51395797 1.08171756 0.34028077\n",
      "  0.71506158 0.78007553 0.60058408 0.88476096 0.7116609  0.6561633\n",
      "  1.51746362]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pred_cols = [f\"R{i+1}_A_win\" for i in range(13)]\n",
    "\n",
    "X = j[pred_cols]\n",
    "y = j['Team_A_win']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,shuffle=True, stratify=y, random_state=42)\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "train_pred=model.predict(X_train)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(\"mean of true values:\",y_test.mean())\n",
    "print(\"mean of predicted values:\",y_pred.mean())\n",
    "print(\"accuracy:\",acc)\n",
    "print(\"coefficients:\",model.coef_)\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "120c8bda-d948-46b1-a93b-941b84192ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.748387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy\n",
       "0  0.748387"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'accuracy':[acc]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "229cec8c-f93e-4efb-9ebd-a79f3aacca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_y_train': [0.5211038961038961],\n",
       " 'mean_y_test': [0.4838709677419355],\n",
       " 'mean_train_pred': [0.5405844155844156],\n",
       " 'mean_test_pred': [0.5032258064516129],\n",
       " 'train_acc': [0.788961038961039],\n",
       " 'test_acc': [0.7483870967741936],\n",
       " 'coefficients': [array([[1.21, 0.48, 0.83, 0.51, 1.08, 0.34, 0.72, 0.78, 0.6 , 0.88, 0.71,\n",
       "          0.66, 1.52]])]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_dictionary = {\\\n",
    "    \"mean_y_train\":[],\n",
    "    \"mean_y_test\":[],\n",
    "    \"mean_train_pred\":[],\n",
    "    \"mean_test_pred\":[],\n",
    "    \"train_acc\":[],\n",
    "    \"test_acc\" :[],\n",
    "    \"coefficients\":[]\n",
    "    }\\\n",
    "\n",
    "analysis_dictionary[\"mean_y_train\"].append(np.mean(y_train))\n",
    "analysis_dictionary[\"mean_y_test\"].append(np.mean(y_test))\n",
    "analysis_dictionary[\"mean_train_pred\"].append(np.mean(train_pred))\n",
    "analysis_dictionary[\"mean_test_pred\"].append(np.mean(y_pred))\n",
    "analysis_dictionary[\"train_acc\"].append(accuracy_score(y_train, train_pred))\n",
    "analysis_dictionary[\"test_acc\"].append(accuracy_score(y_test, y_pred))\n",
    "analysis_dictionary[\"coefficients\"].append(np.round(model.coef_,2))\n",
    "\n",
    "analysis_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e83b5d62-41b8-41ac-8edd-37316bbd6aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rounds_seen</th>\n",
       "      <th>mean_y_train</th>\n",
       "      <th>mean_y_test</th>\n",
       "      <th>mean_train_pred</th>\n",
       "      <th>mean_test_pred</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.483766</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.629870</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>[1.04]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.469156</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.657468</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>[0.22, 1.12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.472403</td>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.663961</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[0.57, 0.97, 0.93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.496753</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.567742</td>\n",
       "      <td>[0.48, 0.93, 0.79, 0.83]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.514610</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>[0.66, 0.85, 0.81, 0.67, 0.96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.676948</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>[0.59, 0.91, 0.82, 0.7, 0.88, 0.66]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.524351</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.706169</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>[0.65, 0.82, 0.83, 0.64, 0.89, 0.55, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.509677</td>\n",
       "      <td>0.719156</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>[0.79, 0.75, 0.82, 0.63, 0.89, 0.51, 0.47, 0.97]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.722403</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>[0.75, 0.77, 0.81, 0.61, 0.9, 0.44, 0.47, 0.87, 0.71]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.524351</td>\n",
       "      <td>0.535484</td>\n",
       "      <td>0.764610</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>[0.77, 0.75, 0.8, 0.57, 0.92, 0.47, 0.44, 0.88, 0.58, 0.77]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.525974</td>\n",
       "      <td>0.503226</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>[0.84, 0.73, 0.86, 0.6, 0.84, 0.42, 0.45, 0.85, 0.58, 0.69, 0.85]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.514610</td>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.754870</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>[0.93, 0.65, 0.9, 0.6, 0.81, 0.42, 0.46, 0.9, 0.59, 0.67, 0.8, 0.71]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.529221</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.801948</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>[1.17, 0.66, 1.02, 0.73, 0.98, 0.48, 0.49, 0.95, 0.65, 0.75, 0.93, 0.7, 1.59]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rounds_seen  mean_y_train  mean_y_test  mean_train_pred  mean_test_pred  \\\n",
       "0             1      0.512987     0.516129         0.483766        0.548387   \n",
       "1             2      0.512987     0.516129         0.469156        0.522581   \n",
       "2             3      0.512987     0.516129         0.472403        0.529032   \n",
       "3             4      0.512987     0.516129         0.496753        0.522581   \n",
       "4             5      0.512987     0.516129         0.514610        0.516129   \n",
       "5             6      0.512987     0.516129         0.521104        0.529032   \n",
       "6             7      0.512987     0.516129         0.524351        0.522581   \n",
       "7             8      0.512987     0.516129         0.517857        0.509677   \n",
       "8             9      0.512987     0.516129         0.534091        0.516129   \n",
       "9            10      0.512987     0.516129         0.524351        0.535484   \n",
       "10           11      0.512987     0.516129         0.525974        0.503226   \n",
       "11           12      0.512987     0.516129         0.514610        0.529032   \n",
       "12           13      0.512987     0.516129         0.529221        0.548387   \n",
       "\n",
       "    train_acc  test_acc  \\\n",
       "0    0.629870  0.619355   \n",
       "1    0.657468  0.593548   \n",
       "2    0.663961  0.600000   \n",
       "3    0.649351  0.567742   \n",
       "4    0.670455  0.638710   \n",
       "5    0.676948  0.638710   \n",
       "6    0.706169  0.683871   \n",
       "7    0.719156  0.670968   \n",
       "8    0.722403  0.677419   \n",
       "9    0.764610  0.709677   \n",
       "10   0.750000  0.690323   \n",
       "11   0.754870  0.690323   \n",
       "12   0.801948  0.722581   \n",
       "\n",
       "                                                                     coefficients  \n",
       "0                                                                          [1.04]  \n",
       "1                                                                    [0.22, 1.12]  \n",
       "2                                                              [0.57, 0.97, 0.93]  \n",
       "3                                                        [0.48, 0.93, 0.79, 0.83]  \n",
       "4                                                  [0.66, 0.85, 0.81, 0.67, 0.96]  \n",
       "5                                             [0.59, 0.91, 0.82, 0.7, 0.88, 0.66]  \n",
       "6                                      [0.65, 0.82, 0.83, 0.64, 0.89, 0.55, 0.55]  \n",
       "7                                [0.79, 0.75, 0.82, 0.63, 0.89, 0.51, 0.47, 0.97]  \n",
       "8                           [0.75, 0.77, 0.81, 0.61, 0.9, 0.44, 0.47, 0.87, 0.71]  \n",
       "9                     [0.77, 0.75, 0.8, 0.57, 0.92, 0.47, 0.44, 0.88, 0.58, 0.77]  \n",
       "10              [0.84, 0.73, 0.86, 0.6, 0.84, 0.42, 0.45, 0.85, 0.58, 0.69, 0.85]  \n",
       "11           [0.93, 0.65, 0.9, 0.6, 0.81, 0.42, 0.46, 0.9, 0.59, 0.67, 0.8, 0.71]  \n",
       "12  [1.17, 0.66, 1.02, 0.73, 0.98, 0.48, 0.49, 0.95, 0.65, 0.75, 0.93, 0.7, 1.59]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_dictionary = {\\\n",
    "        \"rounds_seen\":[],\n",
    "        \"mean_y_train\":[],\n",
    "        \"mean_y_test\":[],\n",
    "        \"mean_train_pred\":[],\n",
    "        \"mean_test_pred\":[],\n",
    "        \"train_acc\":[],\n",
    "        \"test_acc\" :[],\n",
    "        \"coefficients\":[]\n",
    "        }\\\n",
    "\n",
    "analysis_df = pd.DataFrame()\n",
    "\n",
    "for i in range(1,14):\n",
    "    pred_cols = [f\"R{j}_A_win\" for j in range(1,i+1)]\n",
    "    \n",
    "    X = j[pred_cols]\n",
    "    y = j['Team_A_win']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,shuffle=True, stratify=y, random_state=42)\n",
    "\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    train_pred=model.predict(X_train)\n",
    "\n",
    "\n",
    "    \n",
    "    analysis_dictionary[\"rounds_seen\"].append(i)\n",
    "    analysis_dictionary[\"mean_y_train\"].append(np.mean(y_train))\n",
    "    analysis_dictionary[\"mean_y_test\"].append(np.mean(y_test))\n",
    "    analysis_dictionary[\"mean_train_pred\"].append(np.mean(train_pred))\n",
    "    analysis_dictionary[\"mean_test_pred\"].append(np.mean(y_pred))\n",
    "    analysis_dictionary[\"train_acc\"].append(accuracy_score(y_train, train_pred))\n",
    "    analysis_dictionary[\"test_acc\"].append(accuracy_score(y_test, y_pred))\n",
    "    analysis_dictionary[\"coefficients\"].append(np.round(model.coef_[0],2))\n",
    "\n",
    "\n",
    "for feature_name, lst in analysis_dictionary.items():\n",
    "    analysis_df[feature_name] = lst\n",
    "\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e8f343b-8f1e-42c0-a910-a925710922c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ee36a87-2ebf-4d58-8b01-bf5f3a4898ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rounds_seen</th>\n",
       "      <th>mean_y_train</th>\n",
       "      <th>mean_y_test</th>\n",
       "      <th>mean_train_pred</th>\n",
       "      <th>mean_test_pred</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.483766</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.629870</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>[0.6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.469156</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.657468</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>[-0.12, 0.86]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.751623</td>\n",
       "      <td>0.761290</td>\n",
       "      <td>0.612013</td>\n",
       "      <td>0.574194</td>\n",
       "      <td>[-0.13, 0.82, 0.07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.699675</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.650974</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>[-0.23, 0.79, -0.07, 0.33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.813312</td>\n",
       "      <td>0.851613</td>\n",
       "      <td>0.628247</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>[-0.24, 0.76, -0.12, 0.27, 0.19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.808442</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.629870</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>[-0.22, 0.76, -0.1, 0.27, 0.22, -0.07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.808442</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.629870</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>[-0.22, 0.76, -0.1, 0.27, 0.22, -0.07, -0.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.587662</td>\n",
       "      <td>0.561290</td>\n",
       "      <td>[-0.23, 0.74, -0.15, 0.25, 0.19, -0.09, -0.05, 0.21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.582792</td>\n",
       "      <td>0.561290</td>\n",
       "      <td>[-0.25, 0.74, -0.16, 0.25, 0.18, -0.11, -0.06, 0.19, 0.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.855519</td>\n",
       "      <td>0.883871</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.541935</td>\n",
       "      <td>[-0.26, 0.74, -0.18, 0.23, 0.17, -0.12, -0.07, 0.17, 0.07, 0.16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.862013</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.561290</td>\n",
       "      <td>[-0.27, 0.73, -0.19, 0.23, 0.15, -0.14, -0.08, 0.16, 0.06, 0.14, 0.12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.853896</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.584416</td>\n",
       "      <td>0.561290</td>\n",
       "      <td>[-0.26, 0.74, -0.18, 0.23, 0.16, -0.13, -0.08, 0.16, 0.06, 0.15, 0.13, -0.06]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.512987</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.868506</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.582792</td>\n",
       "      <td>0.535484</td>\n",
       "      <td>[-0.28, 0.75, -0.2, 0.24, 0.15, -0.14, -0.09, 0.14, 0.06, 0.14, 0.12, -0.08, 0.15]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rounds_seen  mean_y_train  mean_y_test  mean_train_pred  mean_test_pred  \\\n",
       "0             1      0.512987     0.516129         0.483766        0.548387   \n",
       "1             2      0.512987     0.516129         0.469156        0.522581   \n",
       "2             3      0.512987     0.516129         0.751623        0.761290   \n",
       "3             4      0.512987     0.516129         0.699675        0.735484   \n",
       "4             5      0.512987     0.516129         0.813312        0.851613   \n",
       "5             6      0.512987     0.516129         0.808442        0.832258   \n",
       "6             7      0.512987     0.516129         0.808442        0.832258   \n",
       "7             8      0.512987     0.516129         0.837662        0.864516   \n",
       "8             9      0.512987     0.516129         0.852273        0.864516   \n",
       "9            10      0.512987     0.516129         0.855519        0.883871   \n",
       "10           11      0.512987     0.516129         0.862013        0.890323   \n",
       "11           12      0.512987     0.516129         0.853896        0.890323   \n",
       "12           13      0.512987     0.516129         0.868506        0.890323   \n",
       "\n",
       "    train_acc  test_acc  \\\n",
       "0    0.629870  0.619355   \n",
       "1    0.657468  0.593548   \n",
       "2    0.612013  0.574194   \n",
       "3    0.650974  0.612903   \n",
       "4    0.628247  0.587097   \n",
       "5    0.629870  0.580645   \n",
       "6    0.629870  0.580645   \n",
       "7    0.587662  0.561290   \n",
       "8    0.582792  0.561290   \n",
       "9    0.589286  0.541935   \n",
       "10   0.589286  0.561290   \n",
       "11   0.584416  0.561290   \n",
       "12   0.582792  0.535484   \n",
       "\n",
       "                                                                          coefficients  \n",
       "0                                                                                [0.6]  \n",
       "1                                                                        [-0.12, 0.86]  \n",
       "2                                                                  [-0.13, 0.82, 0.07]  \n",
       "3                                                           [-0.23, 0.79, -0.07, 0.33]  \n",
       "4                                                     [-0.24, 0.76, -0.12, 0.27, 0.19]  \n",
       "5                                               [-0.22, 0.76, -0.1, 0.27, 0.22, -0.07]  \n",
       "6                                        [-0.22, 0.76, -0.1, 0.27, 0.22, -0.07, -0.01]  \n",
       "7                                 [-0.23, 0.74, -0.15, 0.25, 0.19, -0.09, -0.05, 0.21]  \n",
       "8                            [-0.25, 0.74, -0.16, 0.25, 0.18, -0.11, -0.06, 0.19, 0.1]  \n",
       "9                     [-0.26, 0.74, -0.18, 0.23, 0.17, -0.12, -0.07, 0.17, 0.07, 0.16]  \n",
       "10              [-0.27, 0.73, -0.19, 0.23, 0.15, -0.14, -0.08, 0.16, 0.06, 0.14, 0.12]  \n",
       "11       [-0.26, 0.74, -0.18, 0.23, 0.16, -0.13, -0.08, 0.16, 0.06, 0.15, 0.13, -0.06]  \n",
       "12  [-0.28, 0.75, -0.2, 0.24, 0.15, -0.14, -0.09, 0.14, 0.06, 0.14, 0.12, -0.08, 0.15]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_dictionary = {\\\n",
    "        \"rounds_seen\":[],\n",
    "        \"mean_y_train\":[],\n",
    "        \"mean_y_test\":[],\n",
    "        \"mean_train_pred\":[],\n",
    "        \"mean_test_pred\":[],\n",
    "        \"train_acc\":[],\n",
    "        \"test_acc\" :[],\n",
    "        \"coefficients\":[]\n",
    "        }\\\n",
    "\n",
    "analysis_df = pd.DataFrame()\n",
    "\n",
    "for i in range(1,14):\n",
    "    pred_cols = [f\"R{j}_A_win\" for j in range(1,i+1)]\n",
    "    \n",
    "    X = j[pred_cols]\n",
    "    y = j['Team_A_win']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,shuffle=True, stratify=y, random_state=42)\n",
    "\n",
    "    model = LogisticRegression(random_state=42,fit_intercept=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    train_pred=model.predict(X_train)\n",
    "\n",
    "\n",
    "    \n",
    "    analysis_dictionary[\"rounds_seen\"].append(i)\n",
    "    analysis_dictionary[\"mean_y_train\"].append(np.mean(y_train))\n",
    "    analysis_dictionary[\"mean_y_test\"].append(np.mean(y_test))\n",
    "    analysis_dictionary[\"mean_train_pred\"].append(np.mean(train_pred))\n",
    "    analysis_dictionary[\"mean_test_pred\"].append(np.mean(y_pred))\n",
    "    analysis_dictionary[\"train_acc\"].append(accuracy_score(y_train, train_pred))\n",
    "    analysis_dictionary[\"test_acc\"].append(accuracy_score(y_test, y_pred))\n",
    "    analysis_dictionary[\"coefficients\"].append(np.round(model.coef_[0],2))\n",
    "\n",
    "\n",
    "for feature_name, lst in analysis_dictionary.items():\n",
    "    analysis_df[feature_name] = lst\n",
    "\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45585481-cb15-434f-8789-a11aa30a325e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
